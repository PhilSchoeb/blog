---
layout: post
title: Milestone 2
---

## Suivi des expériences

Nos modèles et leurs performances associées peuvent être trouvés [ici](https://wandb.ai/IFT6758-2024-A05/projects)

## Ingénierie des caractéristiques

En utilisant notre fonction load_events_dataframe de la milestone 1, nous pouvons charger les données pour les saisons qui nous intéresse.

### Question 1 :

#### Angle et distance par rapport au filet

Les caractéristiques de distance et d'angle par rapport au filet avaient déjà été ajoutées lors du premier jalon.
Nous avons tout de même ajusté la caractéristique `goal_angle` pour qu'elle soit comprise entre -180 et 180 degrés,
ce qui n'était pas le cas dans la version précédente.
Les valeurs négatives correspondent à un angle à gauche du point de vue du gardien de but, tandis que les valeurs 
positives correspondent à un angle à droite du point de vue du gardien de but.
La valeur 0 correspond à un tir en face du gardien de but, tandis que les valeurs plus grandes que 90 ou plus petites 
que -90 correspondent à un angle derrière le gardien de but. Ceci peut avoir lieu lors d'un rebond.

Voici un schéma illustrant l'angle du tir par rapport au filet :

<img class="figure" src="/images/player_to_goal_2.png" />

#### Filet vide

Nous avons ajouté la caractéristique `is_empty_net` pour indiquer si le filet était vide lors du tir.
Pour ce faire, nous avons utilisé les données `situationCode`, `eventOwnerTeamId` et `homeTeam` pour déterminer si le
gardien de but adverse était présent ou non dans le filet lors du tir.

#### Cible de l'apprentissage supervisé

Nous avons ajouté la caractéristique `is_goal` à partir de la colonne `event_type` pour indiquer si un tir a abouti à un but.
Cette caractéristique booléenne servira de cible pour l'apprentissage supervisé.

#### Figures

<img src="/images/feature_engineering_1/distance_distribution.png" />

Si on s'intéresse à la distribution des tirs en fonction de la distance, on observe que la majorité des tirs sont faits à moins de 60 pieds du but.

<img src="/images/feature_engineering_1/angle_distribution.png" />

Pour ce qui est de l'angle du tir par rapport au but, on voit que la plupart des buts sont réalisés juste en face du filet avec des angles proches de 0. On voit aussi une certaine symmétrie des données, où il y a pratiquement autant de buts et de tirs des deux côtés du filet.

<img src="/images/feature_engineering_1/joint_plot.png" />

Enfin, le joint plot nous montre que plus on est loin du filet, plus l'angle de tir par rapport au filet est assez réduit. A l'inverse, plus on s'approche du filet, plus on observe que les tirs ont tendance à avoir des angles bien plus grands, voir même très grands pour certains, notamment puisqu'on va retrouver ici des tirs qui se font derrière le filet.

### Question 2 :

Si maintenant on s'intérresse uniquement au taux de but et sa relation à la distance, on observe que entre 0 et 60 pieds depuis le filet, la relation est plutôt linéaire, avec un plus haut succès plus on se rapproche du filet. Cependant, à partir d'au-delà de 60 pieds, la relation est plus uniforme, et pour de grandes distances on se retrouve à autour d'environ 9% de succès.

<img src="/images/feature_engineering_1/distance_success_rate.png" />

Pour ce qui est de l'angle de tir par rapport au milieu du filet (qui représente 0 dégré), on voit qu'on a tendance à avoir une relation plutôt linéaire, si on prend la valeur absolue de l'angle et qu'on néglige de quel côté se fait le tir, jusqu'à 90 degrès. Effectivement, plus on s'éloigne de 0 degrés plus le taux de succès baisse. Cependant au-delà d'un angle de 90 degrès (donc quand on passe derrière le filet), la tendance s'inverse. On a également quelques données de tirs qui se font à des angles très extrêmes avec des taux de succès de 100%. Cela pourrait représenter de très rares tirs sur l'ensemble de données, d'ailleurs au-delà de 90 degrès d'angle, on ne parle que des 0.6% de notre ensemble de données. Ces données sont peut-être donc à négliger, ou pourraient être des données aberrantes. 

<img src="/images/feature_engineering_1/angle_success_rate.png" />

### Question 3 :

Si on s'intéresse à la relation entre distance, s'il y a un goal dans le filet ou non et le taux de buts associé, les données semblent globalement logiques cependant certaines observations pourraient laisser penser qu'il y a des données aberrantes. Le taux de buts est toujours plus haut quand le goal est absent, sauf pour des distances entre 80 et 100 pieds. Le taux de buts reste relativement bas à mesure qu'on s'éloigne du filet quand le goal est présent dans le filet (en-dessous de 10%). On pourrait considérer quel cela reste haut, cependant, on ne prend pas ici en compte le nombre de tirs, et on sait que l'énorme majorité des tirs se font à moins de 60 pieds du filet comme on l'a vu au début. Donc ces événements restent très rares in fine. Les hauts taux de buts à une grande distance du filet quand le goal est absent correspondent probablement aux moments où le goal quitte le filet en fin de partie et où des tirs d'une grande distance peuvent être produits. En conclusion, les données ne semblent pas trop aberrantes ici. 

<img src="/images/feature_engineering_1/distance_success_rate_net_status.png" />

Cependant, il est important de rappeler que dans la milestone 1 nous avions utilisé des méthodes pour nous débarasser au préalable de certaines données aberrantes = inclure ce qu'on a fait.

## Modèles de base

En runnant le fichier simple_models.py tel que python -m simple_models.simple_models, on peut séparer nos données en ensemble d'entraînement et de validation et sauver les résultats sur wandb tout en produisant des graphiques mêlant les métriques tous nos modèles simples ensemble.

### Question 1 :

Nous avons produit nos divisions d'entraînement et de validations en chargeant les données des saisons 2016 à 2019, puis en séparant aléatoirement 20% des données pour l'ensemble de validation. 

Pour le modèle de classification logistique avec la distance par rapport au goal et les paramètres par défaut on obtient une précision de 0.9039698177763522. Cependant si on regarde les prédictions faites en terme des étiquettes attribuées, comme montré sur la matrice de confusion ci-dessous, on observe que le modèle n'a pas été capable de prédire un seul but. Il estime que tous tirs sont des non-buts. 

<img src="/images/simple_models/confusion_matrix.png" />

Cela nous indique que la précision en tant que tel n'est pas une métrique suffisante pour évaluer la qualité de notre classifieur logisitique. Effectivement, ce chiffre de 90% correspond en fait à la quantité de non-buts sur notre ensemble de tirs. Le modèle est incapable de classifier les buts comme buts, mais classifie tout comme non-buts. Sauf que 90% des données sont des non-buts.

### Question 2 :

Pour les visualisations, le fichier graphs.py offre plusieurs fonctions, notamment une qui crée les 4 visualisations (four_graphs, intéressant pour les sauver sur l'entrée wandb associée avec le modèle), et une autre qui combine qui permet d'avoir des visualisations multi-modèles (four_graphs_multiple_models).

### Question 3 :

Les résultats pour nos 3 modèles simples en plus d'une ligne de base aléatoire sont les suivants:

<img src="/images/simple_models/roc_curve.png" />

La courbe ROC nous indique que les modèles basés sur la distance et celui combinant distance et angle ont le mieux fonctionné, avec un AUC de 0.70. Le modèle basé sur l'angle peine à faire mieux que le modèle aléatoire.

<img src="/images/simple_models/goal_rate.png" />

<img src="/images/simple_models/cumul_goal_prop.png" />

Le graphique du taux de buts sur les centiles des probabilités nous confirme un peu plus cela, et nous indique également que nos deux "meilleurs" modèles simples produisent des résultats similaires. De même pour celui du nombre de buts cumulé.

<img src="/images/simple_models/calibration_curve.png" />

Enfin la courbe de calibration nous montre comment performent nos modèles. On observe que les principales limitations de nos modèles ici est qu'ils ne sont pas capables de prédire une grande variabilité de probabilités. Les modèles les plus performants ici sont capables de prédire correctement des probabilités de taux de buts jusqu'à 20%, qui correspondent aux taux de buts réellement observés. 

Ainsi, on a ici des modèles qui nous montrent que la distance peut être intéressante pour prédire les taux de buts, mais sa puissance en tant que feature est assez limitée puisqu'elle prédit seulement une fraction des probabilités possibles.  

### Question 4 :

Pour chaque entrée wandb on a: la précision, les métriques de performances (graphiques) et un fichier joblib en artifact pour télécharger le modèle.

Classifieur logique - [distance](https://wandb.ai/IFT6758-2024-A05/simple_model_logistic_regression/runs/7772lzd5)

Classifieur logique - [angle](https://wandb.ai/IFT6758-2024-A05/simple_model_logistic_regression/runs/ture99jg)

Classifieur logique - [distance et angle](https://wandb.ai/IFT6758-2024-A05/simple_model_logistic_regression/runs/mll0tete)

## Ingénierie des caractéristiques II
### Liste des caractéristiques créées

| **Nom de la colonne**               | **Description lisible par un humain**                                                                                             |
|-------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| **time_in_period_seconds**          | Temps écoulé dans la période actuelle, converti en secondes à partir du format `MM:SS`.                                           |
| **game_seconds**                    | Nombre total de secondes écoulées dans le jeu, calculé comme : `(period_number - 1) * 1200 + time_in_period_seconds`.             |
| **last_event_type**                 | Type de l’événement précédent (par exemple, `shot-on-goal`, `blocked-shot`, `goal`, etc.).                                        |
| **last_x**                          | Coordonnée X de l’événement précédent (sur le terrain).                                                                           |
| **last_y**                          | Coordonnée Y de l’événement précédent (sur le terrain).                                                                           |
| **time_since_last_event**           | Temps écoulé (en secondes) depuis l’événement précédent.                                                                          |
| **distance_from_last_event**        | Distance entre les coordonnées (X, Y) de l’événement précédent et celles de l’événement actuel (en unités du terrain).            |
| **is_rebound**                      | Indicateur booléen : `True` si l’événement précédent était un tir (`shot-on-goal`, `missed-shot`, `blocked-shot`), sinon `False`. |
| **speed**                           | Vitesse calculée comme : `distance_from_last_event / time_since_last_event`. Si le temps écoulé est 0, vitesse = 0.               |
| **last_angle**                      | Angle du tir précédent (en degrés) par rapport au filet.                                                                          |
| **absolute_angle_change**           | Changement d’angle absolu entre le tir actuel et le tir précédent, calculé comme : `abs(goal_angle) + abs(last_angle)`.           |
| **power_play_time_elapsed (BONUS)** | Temps écoulé (en secondes) depuis le début de l’avantage numérique (jeu de puissance). Réinitialisé à 0 en fin de pénalité.       |
| **shooting_team_skaters (BONUS)**   | Nombre de patineurs sur glace pour l'équipe effectuant le tir.                                                                    |
| **opposing_team_skaters (BONUS)**   | Nombre de patineurs sur glace pour l'équipe adverse.                                                                              |


---

Lien vers l'expérience qui stocke l'artefact DataFrame filtré pour le jeu spécifié :

https://wandb.ai/IFT6758-2024-A05/ift6758-milestone-2/artifacts/dataset/wpg_v_wsh_2017021065/v1/files

## Modèles avancés

### Question 1 :

Voici les 4 figures demandées :

<img src="/images/roc_basic_xgboost.png" alt="ROC Curve" />
<img src="/images/goal_rate_vs_proba_basic_xgboost.png" alt="Goal Rate vs Probability" />
<img src="/images/cumul_goal_prop_vs_proba_basic_xgboost.png" alt="Cumulative Goal Propensity vs Probability" />
<img src="/images/calibration_curve_basic_xgboost.png" alt="Calibration Curve" />

La configuration de l'ensemble d'entrainement et de validation s'est faite de même manière qu'à la partie 3 (modèles simples). C'est-à-dire une séparation 80-20 aléatoire (même seed pour les deux parties).

Comparaison des résultats à la régression logistique.

### Question 2 :

Premièrement, voici les hyperparamètres que nous avons optimisés ainsi que leur différentes options testées :

Booster = "gbtree" ou "dart"

eta = 0.1, 0.3, 0.5 ou 0.8

gamma = 0, 10 ou 100

max_depth = 4, 6, 8 ou 12

Notre méthode d'optimisation a été d'effectuer une recherche par grille avec une validation non croisée. Nous avons fait ce choix pour pouvoir tester toutes les 96 configurations possibles sans que le temps de computation soit trop élevé. Il est important de noter que nous avons tenté d'optimiser l'AUC (area under curve) par la sélection des hyperparamètres car nous nous intéressons uniquement aux probabilités qu'il y ait un but.

Regardons maintenant l'influence de chaque hyperparamètre, en supposant faussement qu'ils sont indépendants les uns par rapport aux autres, sur l'accuracy et l'AUC moyenne :

<img src="/images/booster.png" alt="Booster config" />
<img src="/images/eta.png" alt="eta config" />
<img src="/images/gamma.png" alt="gamma config" />
<img src="/images/max_depth.png" alt="max_depth config" />

On peut voir que le choix de booster ne semble pas avoir d'effet, mais les autres hyperparamètres peuvent être optimisés. En prenant la configuration qui maximise l'AUC, nous avons sélectionné la configuration suivante: 

Booster = "gbtree", eta = 0.3, gamma = 0 et max_depth = 8. 

Voici une visualisation pour s'en convaincre :

<img src="/images/roc_curve_hp.png" alt="Roc curve for all different hyperparameters configuration" />

Voici maintenant les quatres figures demandées pour notre modèle sélectionné :

<img src="/images/roc_best_xgboost_gbtree_0.3_0_8.png" alt="ROC Curve" />
<img src="/images/goal_rate_vs_proba_best_xgboost_gbtree_0.3_0_8.png" alt="Goal Rate vs Probability" />
<img src="/images/cumul_goal_prop_vs_proba_best_xgboost_gbtree_0.3_0_8.png" alt="Cumulative Goal Propensity vs Probability" />
<img src="/images/calibration_curve_best_xgboost_gbtree_0.3_0_8.png" alt="Calibration Curve" />

En comparant ces figures à celles obtenues à la partie 5.1, on voit que la courbe ROC a la même forme mais son aire sous la courbe est supérieure maintenant. Par rapport, à la figure du goal_rate en fonction du centile de la probabilité prédite, on constate qu'une augmentation du centile a maintenant plus de chance qu'avant d'augmenter le taux de but et aussi que le taux de but augmente quasi exponentielle à partir du 80e centile. On observe aussi que la valeur maximale de goal_rate atteinte est deux fois plus grande. Passons à la figure du pourcentage cumulatif de buts en fonction du centile de la probabilité prédite. Ici, on voit que la courbe est plus prononcée et cela implique qu'il y a beaucoup moins de buts parmi les points prédits à probabilité basse et inversement, il y a plus de points prédits à haute probabilité qui sont des buts. Finalement, on observe la courbe de calibration et on voit directement que les probabilités prédites sont plus élevées. Nos deux courbes suivent assez bien la droite optimale et les deux prédisent des probabilités un peu trop basses pour les plus grandes probabilités prédites.

Avant de conclure sur cette question, juste mentionner que nous avons réalisé que l'hyperparamètre num_round (pour nombre de rounds) représente le nombre d'arbres "boosted" utilisés. Cela fait de num_round le principal hyperparamètre de XGBoost et pourtant nous ne l'avions pas optimisé, donc nous l'avons évalué de manière indépendante, par manque de temps, à partir de l'accuracy et l'AUC pour notre configuration choisie avec différents num_rounds :

num_rounds = 2, 5, 10, 15, 20 et 30

Voici le résultat obtenu :

<img src="/images/num_rounds.png" alt="num_rounds" />

Assez ironiquement, on voit que la valeur par défaut (10) est la meilleure donc nous sélectionnons pour notre configuration finale num_rounds = 10.

Pour finir, voici le lien de l'expérience sur Wandb :

https://wandb.ai/IFT6758-2024-A05/best%20xgboost 

### Question 3 :

## Expérimentation de modèles

### Préparation des données pour les modèles

Nous avons mis en commun la préparation des données pour les modèles avancés.

Pour cela, nous avons développé une fonction `load_train_val_test_x_y` qui charge les saisons 2016 à 2020 en DataFrame.
Les saisons 2016 à 2019 sont utilisées pour l'entraînement et la saison 2020 pour le test.
De là, autre séparation est effectuée pour obtenir les données d'entraînement et de validation.
Au final, nous avons 6 Dataframes :

- `X_train` : les données d'entraînement. 80% des événements des saisons 2016 à 2019.
- `y_train` : les cibles d'entraînement. Colonne `is_goal`.
- `X_val` : les données de validation. 20% des événements des saisons 2016 à 2019.
- `y_val` : les cibles de validation.
- `X_test` : les données de test. Saison 2020 sans la colonne `is_goal`.
- `y_test` : les cibles de test.

Afin de n'inclure aucune donnée relative aux événements `goal`, ce qui conduirait à un overfitting,
nous avons retiré un grand nombre de colonnes des DataFrames `X_train`, `X_val` et `X_test`.

Cette fonction peut être utilisée comme ceci :

```python
from ift6758.features import load_train_val_test_x_y
X_train, y_train, X_val, y_val, X_test, y_test = load_train_val_test_x_y(test_size=0.2)
```

#### Pipeline Scikit-learn

Nous avons créer un pipeline Scikit-learn pour préparer les données avant de les envoyer dans les modèles.
Cette deuxième préparation consiste à encoder les variables catégorielles, imputer les valeurs manquantes et normaliser les données.
En respectant l'interface Scikit-learn, ce pipeline peut être utilisé dans un autre pipeline Scikit-learn.
Par exemple :

```python
from ift6758.features import get_preprocessing_pipeline
from sklearn.pipeline import make_pipeline

preprocessing_pipeline = get_preprocessing_pipeline()
pipeline = make_pipeline(preprocessing_pipeline, model)
```

#### Model trainer

Enfin, nous avons créé une fonction `train_and_val_model` afin d'abstraite la procédure d'entraînement, de validation 
et de sauvegarde des résultats dans Weights & Biases. Cette méthode prend en argument le modèle à entraîner
(incluant le pipeline de preprocessing) puis quelques méta-informations sur l'expérience.

Ceci nous permet de ne pas répéter le code d'entraînement et de validation pour chaque modèle.

Le chargement des données fournit par la fonction `load_train_val_test_x_y` est relativement long (environ 4 minutes).
Ce qui est normal compte tenu de la quantité de données à traiter pour obtenir les DataFrames de la partie 
**Ingénierie des caractéristiques II**.

Pour remédier à ce problème, la fonction `train_and_val_model` garde en cache les DataFrames dans des fichiers `.pkl`
pour les recharger plus rapidement entre chaque entraînement de modèle.

### Question 1 :

#### Random Forest

Nous avons entraîné un modèle Random Forest (fichier `advanced_models/random_forest.py`) et effectué une recherche par
grille pour optimiser les hyperparamètres. Les résultats se trouvent dans le projet `random_forest` sur Weights & Biases.

Le meilleur modèle a été entraîné avec les hyperparamètres suivants :

- `n_estimators` : 1000
- `max_depth` : 18

Son score AUC sur les données de validation est de **0.74252**.

<img class="figure" src="/images/models/random_forest/calibration_curve_random_forest.png" />
<img class="figure" src="/images/models/random_forest/cumul_goal_prop_vs_proba_random_forest.png" />
<img class="figure" src="/images/models/random_forest/goal_rate_vs_proba_random_forest.png" />
<img class="figure" src="/images/models/random_forest/roc_random_forest.png" />

#### SVM

Nous avons également entraîné un modèle SVM (fichier `advanced_models/svm.py`) et effectué une recherche par grille pour
optimiser les hyperparamètres. Les résultats se trouvent dans le projet `svm` sur Weights & Biases.

Les résultats de ce modèle sont très médiocres, avec un score AUC sur les données de validation de **0.57** au mieux.

Il n'est pas la peine de présenter les figures pour ce modèle.

### Question 2 :

## Évaluation sur l'ensemble de test

### Question 1 :

### Question 2 :

